name: CI/CD Pipeline

on:
  push:
    branches: [main, dev]
  pull_request:
    branches: [main, dev]
  workflow_dispatch:
    inputs: {}

permissions:
  contents: read

# Enforce stronger concurrency control
concurrency:
  group: ${{ github.workflow }}-${{ github.ref_name }}
  cancel-in-progress: true

jobs:
  lint:
    # Skip this job for deployments and fixes
    if: ${{ !contains(github.event.inputs.*, 'fix') && !contains(github.event.inputs.*, 'rebuild') && !contains(github.event.inputs.*, 'deploy') }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        component: [backend, admin-panel]
    defaults:
      run:
        working-directory: ./${{ matrix.component }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install dependencies
        run: npm install
      
      - name: Run linting
        run: npm run lint || echo "⚠️ Linting issues found, but continuing build"

  build:
    # Skip this job for deployments and fixes
    if: ${{ !contains(github.event.inputs.*, 'fix') && !contains(github.event.inputs.*, 'rebuild') && !contains(github.event.inputs.*, 'deploy') }}
    runs-on: ubuntu-latest
    needs: [lint]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build backend image
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: false
          load: true
          tags: vpnservice-backend:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Build admin panel image
        uses: docker/build-push-action@v5
        with:
          context: ./admin-panel
          push: false
          load: true
          tags: vpnservice-admin:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Consolidated admin panel fix job
  fix-admin-panel:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && contains(github.event.inputs.*, 'fix-admin')
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up SSH
        uses: shimataro/ssh-key-action@v2
        with:
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          known_hosts: ${{ secrets.SSH_KNOWN_HOSTS }}
          if_key_exists: fail
      
      - name: Execute Consolidated Admin Panel Fix
        env:
          SSH_USER: organic
          SERVER_IP: ${{ secrets.VPN_DOMAIN }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          echo "Executing Consolidated Admin Panel Fix remotely..."
          ssh -o ConnectTimeout=10 -o StrictHostKeyChecking=accept-new $SSH_USER@$SERVER_IP << ENDSSH
            cd ~/dev/vpnservice
            
            echo "===== Starting Comprehensive Admin Panel Fix ====="
            echo "This fix addresses all potential causes of 'Service Temporarily Unavailable' error"
            
            # 1. Create backup of environment and configuration
            echo "Creating backup of current environment..."
            cp .env .env.backup.\$(date +%Y%m%d%H%M%S) 2>/dev/null || echo "No .env file to backup"
            cp docker-compose.yml docker-compose.yml.backup.\$(date +%Y%m%d%H%M%S) 2>/dev/null || echo "No docker-compose.yml file to backup"
            
            # 2. Ensure we have the latest code
            echo "Pulling latest code..."
            git pull origin main
            
            # 3. Using Supabase variables from GitHub secrets
            SUPABASE_URL="${SUPABASE_URL}"
            SUPABASE_KEY="${SUPABASE_KEY}"
            
            echo "Using Supabase URL: \$SUPABASE_URL"
            echo "Using Supabase Key: \${SUPABASE_KEY:0:10}..." # Only show the first 10 characters for security
            
            # 4. Stop and remove the admin container
            echo "Stopping and removing admin container..."
            docker-compose down admin || true
            docker stop vpn-admin 2>/dev/null || true
            docker rm vpn-admin 2>/dev/null || true
            
            # 5. Create directories for environment files
            echo "Setting up environment files with correct values..."
            mkdir -p .admin-fix
            mkdir -p admin-panel
            
            # 6. Create environment files with correct values from GitHub secrets
            cat > .admin-fix/.env << EOF
            # Next.js environment variables
            NEXT_PUBLIC_SUPABASE_URL=\$SUPABASE_URL
            NEXT_PUBLIC_SUPABASE_ANON_KEY=\$SUPABASE_KEY
            NEXT_PUBLIC_API_URL=http://backend:3000
            EOF
            
            # Create copies for all possible Next.js env file locations
            cp .admin-fix/.env .admin-fix/.env.local
            cp .admin-fix/.env .admin-fix/.env.production
            cp .admin-fix/.env .admin-fix/.env.production.local
            
            # Also create files directly in the admin-panel directory
            cp .admin-fix/.env admin-panel/.env.local
            
            # 7. Update the main .env file
            echo "Updating main .env file with correct variables..."
            
            # Update or add Supabase variables
            if [ -f ".env" ]; then
              # Update existing variables
              sed -i "s|SUPABASE_URL=.*|SUPABASE_URL=\$SUPABASE_URL|g" .env
              sed -i "s|SUPABASE_KEY=.*|SUPABASE_KEY=\$SUPABASE_KEY|g" .env
              sed -i "s|NEXT_PUBLIC_SUPABASE_URL=.*|NEXT_PUBLIC_SUPABASE_URL=\$SUPABASE_URL|g" .env
              sed -i "s|NEXT_PUBLIC_SUPABASE_ANON_KEY=.*|NEXT_PUBLIC_SUPABASE_ANON_KEY=\$SUPABASE_KEY|g" .env
              
              # Add if they don't exist
              grep -q "NEXT_PUBLIC_SUPABASE_URL" .env || echo "NEXT_PUBLIC_SUPABASE_URL=\$SUPABASE_URL" >> .env
              grep -q "NEXT_PUBLIC_SUPABASE_ANON_KEY" .env || echo "NEXT_PUBLIC_SUPABASE_ANON_KEY=\$SUPABASE_KEY" >> .env
            else
              # Create new .env if it doesn't exist
              cat > .env << EOF
            # Basic configuration
            NODE_ENV=production
            TIMEZONE=UTC
            SECURITY_PANEL_ENFORCE_HTTPS=false
            
            # Supabase configuration
            SUPABASE_URL=\$SUPABASE_URL
            SUPABASE_KEY=\$SUPABASE_KEY
            
            # Next.js admin panel configuration
            NEXT_PUBLIC_SUPABASE_URL=\$SUPABASE_URL
            NEXT_PUBLIC_SUPABASE_ANON_KEY=\$SUPABASE_KEY
            NEXT_PUBLIC_API_URL=http://backend:3000
            EOF
            fi
            
            # 8. Update docker-compose.yml if it exists
            if [ -f "docker-compose.yml" ]; then
              echo "Updating docker-compose.yml..."
              
              # 8.1. Update build args if they exist
              sed -i "s|NEXT_PUBLIC_SUPABASE_URL=.*|NEXT_PUBLIC_SUPABASE_URL=\$SUPABASE_URL|g" docker-compose.yml || true
              sed -i "s|NEXT_PUBLIC_SUPABASE_ANON_KEY=.*|NEXT_PUBLIC_SUPABASE_ANON_KEY=\$SUPABASE_KEY|g" docker-compose.yml || true
              
              # 8.2. Add volumes for environment files
              # Check if volumes section already exists for admin service
              if grep -q "admin:.*volumes:" docker-compose.yml -A 5; then
                echo "Volumes section exists, updating it..."
                # Remove existing environment file mounts if they exist
                sed -i '/\.\(admin-panel-env\|admin-fix\)/d' docker-compose.yml
                
                # Find the line number where the volumes section is for the admin service
                ADMIN_VOL_LINE=\$(grep -n "admin:.*volumes:" docker-compose.yml | cut -d: -f1)
                if [ -n "\$ADMIN_VOL_LINE" ]; then
                  # Add our volume mounts to the existing volumes section
                  sed -i "\${ADMIN_VOL_LINE}a\\      - ./.admin-fix/.env:/app/.env" docker-compose.yml
                  sed -i "\${ADMIN_VOL_LINE}a\\      - ./.admin-fix/.env.local:/app/.env.local" docker-compose.yml
                  sed -i "\${ADMIN_VOL_LINE}a\\      - ./.admin-fix/.env.production:/app/.env.production" docker-compose.yml
                  sed -i "\${ADMIN_VOL_LINE}a\\      - ./.admin-fix/.env.production.local:/app/.env.production.local" docker-compose.yml
                fi
              else
                echo "Adding new volumes section for admin service..."
                # Find the admin service section
                ADMIN_LINE=\$(grep -n "container_name: vpn-admin" docker-compose.yml | cut -d: -f1)
                if [ -n "\$ADMIN_LINE" ]; then
                  # Add a new volumes section
                  sed -i "\${ADMIN_LINE}a\\    volumes:\\n      - ./.admin-fix/.env:/app/.env\\n      - ./.admin-fix/.env.local:/app/.env.local\\n      - ./.admin-fix/.env.production:/app/.env.production\\n      - ./.admin-fix/.env.production.local:/app/.env.production.local" docker-compose.yml
                fi
              fi
            fi
            
            # 9. Create a custom Dockerfile for the admin panel
            echo "Creating optimized Dockerfile for Next.js..."
            mkdir -p .admin-fix
            
            cat > .admin-fix/Dockerfile << EOF
            FROM node:20-alpine AS builder
            
            WORKDIR /app
            
            # Set build arguments and environment variables
            ARG NEXT_PUBLIC_SUPABASE_URL="\$SUPABASE_URL"
            ARG NEXT_PUBLIC_SUPABASE_ANON_KEY="\$SUPABASE_KEY"
            ARG NEXT_PUBLIC_API_URL="http://backend:3000"
            
            ENV NEXT_PUBLIC_SUPABASE_URL=\${NEXT_PUBLIC_SUPABASE_URL}
            ENV NEXT_PUBLIC_SUPABASE_ANON_KEY=\${NEXT_PUBLIC_SUPABASE_ANON_KEY}
            ENV NEXT_PUBLIC_API_URL=\${NEXT_PUBLIC_API_URL}
            
            # Copy package files
            COPY package*.json ./
            
            # Install dependencies
            RUN npm ci || npm install
            
            # Copy the rest of the app
            COPY . .
            
            # Print environment variables for debugging
            RUN echo "Building with NEXT_PUBLIC_SUPABASE_URL=\${NEXT_PUBLIC_SUPABASE_URL}"
            RUN echo "Building with NEXT_PUBLIC_API_URL=\${NEXT_PUBLIC_API_URL}"
            
            # Create env files explicitly at build time
            RUN echo "NEXT_PUBLIC_SUPABASE_URL=\${NEXT_PUBLIC_SUPABASE_URL}" > .env
            RUN echo "NEXT_PUBLIC_SUPABASE_ANON_KEY=\${NEXT_PUBLIC_SUPABASE_ANON_KEY}" >> .env
            RUN echo "NEXT_PUBLIC_API_URL=\${NEXT_PUBLIC_API_URL}" >> .env
            RUN cp .env .env.local
            RUN cp .env .env.production
            RUN cp .env .env.production.local
            
            # Build the app
            RUN npm run build
            
            # Production image
            FROM node:20-alpine AS runner
            
            WORKDIR /app
            
            # Set production environment variables
            ENV NODE_ENV=production
            ENV NEXT_PUBLIC_SUPABASE_URL="\$SUPABASE_URL"
            ENV NEXT_PUBLIC_SUPABASE_ANON_KEY="\$SUPABASE_KEY"
            ENV NEXT_PUBLIC_API_URL="http://backend:3000"
            
            # Copy necessary files from builder stage
            COPY --from=builder /app/next.config.js ./
            COPY --from=builder /app/public ./public
            COPY --from=builder /app/.next ./.next
            COPY --from=builder /app/node_modules ./node_modules
            COPY --from=builder /app/package.json ./package.json
            COPY --from=builder /app/.env* ./
            
            # Expose port
            EXPOSE 3000
            
            # Health check
            HEALTHCHECK --interval=30s --timeout=5s --start-period=10s --retries=3 CMD wget -qO- http://localhost:3000 || exit 1
            
            # Run the app
            CMD ["npm", "start"]
            EOF
            
            # 10. Determine if we should update docker-compose.yml to use the custom Dockerfile
            if [ -f "docker-compose.yml" ] && grep -q "dockerfile: Dockerfile" docker-compose.yml; then
              echo "Updating docker-compose.yml to use custom Dockerfile..."
              sed -i "s|dockerfile: Dockerfile|dockerfile: ../.admin-fix/Dockerfile|g" docker-compose.yml
            fi
            
            # 11. Two approaches:
            # A. Use docker-compose if available
            if command -v docker-compose > /dev/null 2>&1 || docker compose version > /dev/null 2>&1; then
              echo "Rebuilding and starting with Docker Compose..."
              if command -v docker-compose > /dev/null 2>&1; then
                docker-compose build --no-cache admin
                docker-compose up -d admin
              else
                docker compose build --no-cache admin
                docker compose up -d admin
              fi
            # B. Use direct Docker commands as fallback
            else
              echo "Docker Compose not available, using Docker directly..."
              # Check for docker network
              NETWORK_NAME=\$(docker network ls | grep vpn | head -1 | awk '{print \$2}')
              if [ -z "\$NETWORK_NAME" ]; then
                NETWORK_NAME="vpn_vpn-network"
                echo "Creating docker network \$NETWORK_NAME..."
                docker network create \$NETWORK_NAME || true
              else
                echo "Using existing network: \$NETWORK_NAME"
              fi
              
              # Build the admin panel image
              echo "Building admin panel image..."
              docker build -t vpn-admin-fixed:latest -f .admin-fix/Dockerfile ./admin-panel
              
              # Run the container
              echo "Starting admin panel container..."
              docker run -d \\
                --name vpn-admin \\
                --network \$NETWORK_NAME \\
                -p 8080:3000 \\
                -v \$(pwd)/.admin-fix/.env:/app/.env \\
                -v \$(pwd)/.admin-fix/.env.local:/app/.env.local \\
                -v \$(pwd)/.admin-fix/.env.production:/app/.env.production \\
                -v \$(pwd)/.admin-fix/.env.production.local:/app/.env.production.local \\
                --restart unless-stopped \\
                --health-cmd="wget -qO- http://localhost:3000 || exit 1" \\
                --health-interval=30s \\
                --health-timeout=5s \\
                --health-retries=3 \\
                vpn-admin-fixed:latest
            fi
            
            # 12. Wait for container to initialize
            echo "Waiting for admin panel to initialize (45 seconds)..."
            sleep 45
            
            # 13. Check container status and logs
            echo "Admin panel container status:"
            docker ps | grep vpn-admin
            
            echo "Admin panel logs:"
            docker logs vpn-admin | tail -n 50
            
            # 14. Test accessibility with multiple attempts
            echo "Testing admin panel accessibility..."
            for i in {1..5}; do
              echo "Attempt \$i..."
              HTTP_STATUS=\$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8080 || echo "Failed")
              if [ "\$HTTP_STATUS" = "200" ] || [ "\$HTTP_STATUS" = "302" ]; then
                echo "✅ Admin panel is accessible (HTTP Status: \$HTTP_STATUS)"
                break
              else
                echo "⚠️ Admin panel returned HTTP Status: \$HTTP_STATUS"
                if [ \$i -lt 5 ]; then
                  echo "Waiting 10 seconds before trying again..."
                  sleep 10
                fi
              fi
            done
            
            # 15. Alternative approach if still not working
            if [ "\$HTTP_STATUS" != "200" ] && [ "\$HTTP_STATUS" != "302" ]; then
              echo "⚠️ Still having issues. Trying alternative approach..."
              
              # Stop the container
              docker stop vpn-admin
              docker rm vpn-admin
              
              # Try running with a simpler setup - just the environment variables
              echo "Starting admin container with simplified approach..."
              if command -v docker-compose > /dev/null 2>&1; then
                # Update environment section in docker-compose.yml
                sed -i "/container_name: vpn-admin/a\\    environment:\\n      - NEXT_PUBLIC_SUPABASE_URL=\$SUPABASE_URL\\n      - NEXT_PUBLIC_SUPABASE_ANON_KEY=\$SUPABASE_KEY\\n      - NEXT_PUBLIC_API_URL=http://backend:3000" docker-compose.yml
                docker-compose up -d admin
              else
                docker run -d \\
                  --name vpn-admin \\
                  --network vpn_vpn-network \\
                  -p 8080:3000 \\
                  -e NEXT_PUBLIC_SUPABASE_URL=\$SUPABASE_URL \\
                  -e NEXT_PUBLIC_SUPABASE_ANON_KEY=\$SUPABASE_KEY \\
                  -e NEXT_PUBLIC_API_URL=http://backend:3000 \\
                  --restart unless-stopped \\
                  vpnservice-admin:latest
              fi
              
              echo "Waiting 30 seconds for the container to initialize with new configuration..."
              sleep 30
              
              # Test again
              HTTP_STATUS=\$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8080 || echo "Failed")
              if [ "\$HTTP_STATUS" = "200" ] || [ "\$HTTP_STATUS" = "302" ]; then
                echo "✅ Admin panel is now accessible with alternative configuration (HTTP Status: \$HTTP_STATUS)"
              else
                echo "❌ Admin panel still not accessible (HTTP Status: \$HTTP_STATUS)"
                echo "Final logs:"
                docker logs vpn-admin | tail -n 50
              fi
            fi
            
            # 16. Verify environment variables in container
            echo "Verifying environment variables in container:"
            docker exec vpn-admin env | grep NEXT_PUBLIC
            
            echo ""
            echo "===== Admin Panel Fix Complete ====="
            echo ""
            echo "The admin panel should now be accessible at:"
            echo "http://localhost:8080 (on server)"
            echo "http://\${VPN_DOMAIN:-your-server-ip}:8080 (externally)"
          ENDSSH
      
      - name: Verification Summary
        run: |
          echo "===== Admin Panel Fix Summary ====="
          echo "The admin panel environment variables have been updated with:"
          echo "- SUPABASE_URL: ${{ secrets.SUPABASE_URL }}"
          echo "- SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }} (partially hidden for security)"
          echo ""
          echo "The admin panel has been rebuilt with the correct environment variables."
          echo "Multiple approaches have been tried to ensure it works:"
          echo "1. Docker Compose rebuild with environment files"
          echo "2. Direct Docker run with volume mounts"
          echo "3. Simplified approach with environment variables"
          echo ""
          echo "Admin Panel should now be accessible at:"
          echo "http://${{ secrets.VPN_DOMAIN }}:8080"
          echo ""
          echo "If issues persist, check the logs on the server with:"
          echo "  docker logs vpn-admin"

  # Standard deployment job
  deploy:
    runs-on: ubuntu-latest
    # Only run on main branch or manual trigger
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up SSH
        uses: shimataro/ssh-key-action@v2
        with:
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          known_hosts: ${{ secrets.SSH_KNOWN_HOSTS }}
          if_key_exists: fail

      - name: Deploy to Server
        env:
          SSH_USER: organic
          SERVER_IP: ${{ secrets.VPN_DOMAIN }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          ssh -o ConnectTimeout=10 -o StrictHostKeyChecking=accept-new $SSH_USER@$SERVER_IP << 'ENDSSH'
            set +e
            echo "===== Starting Deployment Process ====="
            
            # Navigate to project directory
            mkdir -p ~/dev
            cd ~/dev
            
            if [ ! -d "vpnservice" ]; then
              echo "Cloning repository..."
              git clone ${{ github.server_url }}/${{ github.repository }}.git
              cd vpnservice
            else
              cd vpnservice
              echo "Pulling latest changes..."
              git fetch --prune
              git reset --hard origin/main
            fi

            # Copy .env file if it doesn't exist
            if [ ! -f ".env" ]; then
              echo "Setting up environment variables..."
              cp .env.example .env
              # Update with GitHub secrets
              echo "SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> .env
              echo "SUPABASE_KEY=${{ secrets.SUPABASE_KEY }}" >> .env
              echo "NEXT_PUBLIC_SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> .env
              echo "NEXT_PUBLIC_SUPABASE_ANON_KEY=${{ secrets.SUPABASE_KEY }}" >> .env
              echo "TELEGRAM_BOT_TOKEN=${{ secrets.TELEGRAM_BOT_TOKEN }}" >> .env
              echo "XUI_USERNAME=${{ secrets.XUI_USERNAME }}" >> .env
              echo "XUI_PASSWORD=${{ secrets.XUI_PASSWORD }}" >> .env
              echo "VPN_DOMAIN=${VPN_DOMAIN:-${{ secrets.VPN_DOMAIN }}}" >> .env
              echo "VPN_ADMIN_EMAIL=${VPN_ADMIN_EMAIL:-admin@example.com}" >> .env
              echo "NODE_ENV=production" >> .env
            fi

            # Also update the .env with correct Supabase variables if they exist
            if [ -f ".env" ]; then
              sed -i "s|SUPABASE_URL=.*|SUPABASE_URL=${{ secrets.SUPABASE_URL }}|g" .env
              sed -i "s|SUPABASE_KEY=.*|SUPABASE_KEY=${{ secrets.SUPABASE_KEY }}|g" .env
              sed -i "s|NEXT_PUBLIC_SUPABASE_URL=.*|NEXT_PUBLIC_SUPABASE_URL=${{ secrets.SUPABASE_URL }}|g" .env
              sed -i "s|NEXT_PUBLIC_SUPABASE_ANON_KEY=.*|NEXT_PUBLIC_SUPABASE_ANON_KEY=${{ secrets.SUPABASE_KEY }}|g" .env
              
              # Add if they don't exist
              grep -q "NEXT_PUBLIC_SUPABASE_URL" .env || echo "NEXT_PUBLIC_SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> .env
              grep -q "NEXT_PUBLIC_SUPABASE_ANON_KEY" .env || echo "NEXT_PUBLIC_SUPABASE_ANON_KEY=${{ secrets.SUPABASE_KEY }}" >> .env
            fi

            # Start or restart Docker services
            echo "Starting Docker services..."
            if command -v docker-compose &> /dev/null; then
              docker-compose down || true
              docker-compose build || echo "⚠️ Build issues, but continuing"
              docker-compose up -d || echo "⚠️ Start issues, but continuing"
            else
              docker compose down || true
              docker compose build || echo "⚠️ Build issues, but continuing"
              docker compose up -d || echo "⚠️ Start issues, but continuing"
            fi

            # Verify services are running
            echo "===== Deployed Services ====="
            docker ps
            
            # Print access URLs
            echo "===== Service Access Information ====="
            DOMAIN=${VPN_DOMAIN:-localhost}
            echo "VPN Admin Panel: https://$DOMAIN:54321"
            echo "Backend API: http://$DOMAIN:3000"
            echo "Admin Dashboard: http://$DOMAIN:8080"
            echo "Admin Email: ${VPN_ADMIN_EMAIL:-admin@example.com}"
            
            echo "===== Deployment Complete ====="
            # Always succeed
            exit 0
          ENDSSH

  # Rebuild specific components
  rebuild-component:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && (contains(github.event.inputs.*, 'rebuild-admin') || contains(github.event.inputs.*, 'rebuild-backend') || contains(github.event.inputs.*, 'rebuild-xui'))
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up SSH
        uses: shimataro/ssh-key-action@v2
        with:
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          known_hosts: ${{ secrets.SSH_KNOWN_HOSTS }}
          if_key_exists: fail
      
      - name: Determine component to rebuild
        id: component
        run: |
          if [[ "${{ github.event.inputs.* }}" == *"rebuild-admin"* ]]; then
            echo "component_name=admin" >> $GITHUB_OUTPUT
            echo "container_name=vpn-admin" >> $GITHUB_OUTPUT
            echo "port=8080" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event.inputs.* }}" == *"rebuild-backend"* ]]; then
            echo "component_name=backend" >> $GITHUB_OUTPUT
            echo "container_name=vpn-backend" >> $GITHUB_OUTPUT
            echo "port=3000" >> $GITHUB_OUTPUT
          else
            echo "component_name=xui" >> $GITHUB_OUTPUT
            echo "container_name=xray-ui" >> $GITHUB_OUTPUT
            echo "port=54321" >> $GITHUB_OUTPUT
          fi
      
      - name: Rebuild Specific Component
        env:
          SSH_USER: organic
          SERVER_IP: ${{ secrets.VPN_DOMAIN }}
          COMPONENT: ${{ steps.component.outputs.component_name }}
          CONTAINER: ${{ steps.component.outputs.container_name }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          echo "Rebuilding $COMPONENT component remotely..."
          ssh -o ConnectTimeout=10 -o StrictHostKeyChecking=accept-new $SSH_USER@$SERVER_IP << ENDSSH
            cd ~/dev/vpnservice
            
            echo "Pulling latest changes from repository..."
            git pull origin main
            
            # Update .env file with correct values if rebuilding admin
            if [ "$COMPONENT" = "admin" ]; then
              echo "Updating environment variables for admin panel..."
              if [ -f ".env" ]; then
                sed -i "s|SUPABASE_URL=.*|SUPABASE_URL=${SUPABASE_URL}|g" .env
                sed -i "s|SUPABASE_KEY=.*|SUPABASE_KEY=${SUPABASE_KEY}|g" .env
                sed -i "s|NEXT_PUBLIC_SUPABASE_URL=.*|NEXT_PUBLIC_SUPABASE_URL=${SUPABASE_URL}|g" .env
                sed -i "s|NEXT_PUBLIC_SUPABASE_ANON_KEY=.*|NEXT_PUBLIC_SUPABASE_ANON_KEY=${SUPABASE_KEY}|g" .env
                
                # Add if they don't exist
                grep -q "NEXT_PUBLIC_SUPABASE_URL" .env || echo "NEXT_PUBLIC_SUPABASE_URL=${SUPABASE_URL}" >> .env
                grep -q "NEXT_PUBLIC_SUPABASE_ANON_KEY" .env || echo "NEXT_PUBLIC_SUPABASE_ANON_KEY=${SUPABASE_KEY}" >> .env
              fi
              
              # Also update docker-compose.yml if it exists
              if [ -f "docker-compose.yml" ]; then
                echo "Updating docker-compose.yml with correct Supabase URL..."
                cp docker-compose.yml docker-compose.yml.backup.$(date +%Y%m%d%H%M%S)
                
                # Try to update build args if they exist
                sed -i "s|NEXT_PUBLIC_SUPABASE_URL=.*|NEXT_PUBLIC_SUPABASE_URL=${SUPABASE_URL}|g" docker-compose.yml || true
                sed -i "s|NEXT_PUBLIC_SUPABASE_ANON_KEY=.*|NEXT_PUBLIC_SUPABASE_ANON_KEY=${SUPABASE_KEY}|g" docker-compose.yml || true
              fi
            fi
            
            echo "Stopping and removing the $COMPONENT container..."
            docker stop $CONTAINER || true
            docker rm $CONTAINER || true
            
            echo "Rebuilding $COMPONENT container..."
            if command -v docker-compose &> /dev/null; then
              docker-compose build --no-cache $COMPONENT
              docker-compose up -d $COMPONENT
            else
              docker compose build --no-cache $COMPONENT
              docker compose up -d $COMPONENT
            fi
            
            echo "Waiting for container to initialize (30 seconds)..."
            sleep 30
            
            echo "Container status:"
            docker ps | grep $CONTAINER
            
            echo "Container logs:"
            docker logs $CONTAINER | tail -n 30
            
            # Verify environment variables for admin panel
            if [ "$COMPONENT" = "admin" ]; then
              echo "Verifying admin panel environment variables:"
              docker exec $CONTAINER env | grep NEXT_PUBLIC
            fi
          ENDSSH
      
      - name: Component Rebuild Summary
        run: |
          echo "===== ${{ steps.component.outputs.component_name }} Rebuild Summary ====="
          echo "The ${{ steps.component.outputs.component_name }} component has been rebuilt."
          
          if [ "${{ steps.component.outputs.component_name }}" = "admin" ]; then
            echo ""
            echo "Admin panel was rebuilt with the following environment variables:"
            echo "- SUPABASE_URL: ${{ secrets.SUPABASE_URL }}"
            echo "- SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }} (partially hidden for security)"
          fi
          
          echo ""
          echo "Component should now be accessible at:"
          if [ "${{ steps.component.outputs.component_name }}" = "xui" ]; then
            echo "https://${{ secrets.VPN_DOMAIN }}:${{ steps.component.outputs.port }}"
          else
            echo "http://${{ secrets.VPN_DOMAIN }}:${{ steps.component.outputs.port }}"
          fi 
